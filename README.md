# LLM Template Project

ä¸€ä¸ªç”¨äºå¿«é€Ÿæ„å»º LLM åº”ç”¨çš„ Python å·¥å…·åŒ…ï¼Œæä¾›äº†é…ç½®ç®¡ç†ã€LLM æ¨¡å‹ç®¡ç†ã€Agent åˆ›å»ºã€æœç´¢å·¥å…·ã€æç¤ºè¯æ¨¡æ¿ç­‰å¸¸ç”¨åŠŸèƒ½çš„å°è£…ï¼Œè®©ä½ å¯ä»¥å¿«é€Ÿä¸Šæ‰‹å¼€å‘åŸºäº LLM çš„åº”ç”¨ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ”§ **é…ç½®ç®¡ç†**ï¼šæ”¯æŒ YAML é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡ç®¡ç†
- ğŸ¤– **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒ OpenAIã€Azureã€Googleã€Dashscopeã€DeepSeekã€Volces ç­‰å¤šç§ LLM æä¾›å•†
- ğŸ” **æœç´¢å·¥å…·**ï¼šé›†æˆ Tavilyã€DuckDuckGoã€Braveã€Arxivã€Wikipedia ç­‰å¤šç§æœç´¢å¼•æ“
- ğŸ’¬ **Agent æ„å»º**ï¼šåŸºäº LangChain/LangGraph çš„ Agent åˆ›å»ºå·¥å…·
- ğŸ“ **æç¤ºè¯æ¨¡æ¿**ï¼šåŸºäº Jinja2 çš„æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿ
- ğŸ§  **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šè‡ªåŠ¨ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒ token é™åˆ¶å’Œæ¶ˆæ¯å‹ç¼©
- ğŸ› ï¸ **å·¥å…·å‡½æ•°**ï¼šJSON ä¿®å¤ã€å‚æ•°æ¸…ç†ç­‰å®ç”¨å·¥å…·

## é¡¹ç›®ç»“æ„

```
llm_template_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # é…ç½®ç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ llms/            # LLM æ¨¡å‹ç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ agents/          # Agent åˆ›å»ºæ¨¡å—
â”‚   â”œâ”€â”€ tools/           # å·¥å…·æ¨¡å—ï¼ˆæœç´¢ç­‰ï¼‰
â”‚   â”œâ”€â”€ prompts/         # æç¤ºè¯æ¨¡æ¿æ¨¡å—
â”‚   â”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â””â”€â”€ graph/           # å›¾çŠ¶æ€ç®¡ç†æ¨¡å—
â”œâ”€â”€ config.yaml          # é…ç½®æ–‡ä»¶
â””â”€â”€ README.md
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install langchain langchain-openai langchain-community langgraph
pip install python-dotenv pyyaml jinja2
pip install json-repair httpx
```

### 2. é…ç½®ç¯å¢ƒ

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
SEARCH_API=tavily  # å¯é€‰: tavily, duckduckgo, brave_search, arxiv, searx, wikipedia
TAVILY_API_KEY=your_tavily_api_key  # å¦‚æœä½¿ç”¨ Tavily
BRAVE_SEARCH_API_KEY=your_brave_key  # å¦‚æœä½¿ç”¨ Brave
```

### 3. é…ç½® LLM

ç¼–è¾‘ `config.yaml`ï¼š

```yaml
BASIC_MODEL:
  base_url: "https://api.openai.com/v1"
  model: "gpt-4"
  api_key: "your-api-key"
  verify_ssl: true
  max_retries: 3
  token_limit: 8000

REASONING_MODEL:
  base_url: "https://api.openai.com/v1"
  model: "gpt-4"
  api_key: "your-api-key"
  token_limit: 8000

VISION_MODEL:
  base_url: "https://api.openai.com/v1"
  model: "gpt-4-vision-preview"
  api_key: "your-api-key"
  token_limit: 8000

CODE_MODEL:
  base_url: "https://api.openai.com/v1"
  model: "gpt-4"
  api_key: "your-api-key"
  token_limit: 8000

SEARCH_ENGINE:
  include_raw_content: true
  include_images: true
  include_image_descriptions: true
  include_domains: []
  exclude_domains: []
```

## æ ¸å¿ƒæ¨¡å—ä½¿ç”¨æŒ‡å—

### 1. é…ç½®ç®¡ç† (`src.config`)

#### åŠ è½½é…ç½®æ–‡ä»¶

```python
from src.config import load_yaml_config

# åŠ è½½ YAML é…ç½®æ–‡ä»¶
config = load_yaml_config("config.yaml")

# é…ç½®æ–‡ä»¶æ”¯æŒç¯å¢ƒå˜é‡æ›¿æ¢
# åœ¨ config.yaml ä¸­ä½¿ç”¨ $ENV_VAR_NAME æ ¼å¼
```

#### æœç´¢å¼•æ“é…ç½®

```python
from src.config import SELECTED_SEARCH_ENGINE, SearchEngine

# è·å–å½“å‰é€‰æ‹©çš„æœç´¢å¼•æ“
print(SELECTED_SEARCH_ENGINE)  # 'tavily'

# æœç´¢å¼•æ“æšä¸¾ç±»å‹
# SearchEngine.TAVILY
# SearchEngine.DUCKDUCKGO
# SearchEngine.BRAVE_SEARCH
# SearchEngine.ARXIV
# SearchEngine.SEARX
# SearchEngine.WIKIPEDIA
```

### 2. LLM æ¨¡å‹ç®¡ç† (`src.llms`)

#### è·å– LLM å®ä¾‹

```python
from src.llms import get_llm_by_type, get_llm_token_limit_by_type

# è·å–æŒ‡å®šç±»å‹çš„ LLM å®ä¾‹ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
llm = get_llm_by_type("basic")  # basic, reasoning, vision, code

# è°ƒç”¨ LLM
from langchain_core.messages import HumanMessage
message = HumanMessage(content="ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
response = llm.invoke([message])
print(response.content)

# è·å–æŒ‡å®šç±»å‹çš„ token é™åˆ¶
token_limit = get_llm_token_limit_by_type("basic")
print(f"Token limit: {token_limit}")
```

#### æ”¯æŒçš„ LLM ç±»å‹

- `basic`: åŸºç¡€æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
- `reasoning`: æ¨ç†æ¨¡å‹ï¼ˆæ”¯æŒæ€ç»´é“¾ï¼‰
- `vision`: è§†è§‰æ¨¡å‹
- `code`: ä»£ç æ¨¡å‹

#### æ”¯æŒçš„å¹³å°

- **OpenAI**: é€šè¿‡ `ChatOpenAI`
- **Azure OpenAI**: é€šè¿‡ `AzureChatOpenAI`ï¼ˆè‡ªåŠ¨æ£€æµ‹ `azure_endpoint`ï¼‰
- **Google AI Studio**: è®¾ç½® `platform: "google_aistudio"`
- **Dashscope**: è‡ªåŠ¨æ£€æµ‹ `dashscope.` åŸŸå
- **DeepSeek**: æ¨ç†ç±»å‹è‡ªåŠ¨ä½¿ç”¨ `ChatDeepSeek`
- **Volces**: é€šè¿‡ `ChatOpenAI` é…ç½®è‡ªå®šä¹‰ `base_url`

### 3. Agent åˆ›å»º (`src.agents`)

#### åˆ›å»º Agent

```python
from src.agents import create_agent_
from src.tools.search import get_web_search_tool
from src.prompts import get_prompt_template
from langchain_core.messages import HumanMessage

# åˆ›å»ºå¸¦æœ‰æœç´¢å·¥å…·çš„ Agent
agent = create_agent_(
    agent_name="my_agent",
    agent_type="basic",  # å¯¹åº” config/agents.py ä¸­çš„æ˜ å°„
    tools=[get_web_search_tool(max_search_results=3)],
    prompt_template=get_prompt_template("test")  # ä» prompts/ ç›®å½•åŠ è½½æ¨¡æ¿
)

# è¿è¡Œ Agent
agent_input = {
    "messages": [
        HumanMessage(content="æŸ¥æ‰¾ä¸ Python æœ€æ–°ç‰ˆæœ¬ç›¸å…³çš„ä¿¡æ¯")
    ]
}

result = agent.invoke(
    input=agent_input,
    config={"recursion_limit": 10}
)
print(result)
```

### 4. æœç´¢å·¥å…· (`src.tools`)

#### ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·

```python
from src.tools.search import get_web_search_tool

# åˆ›å»ºæœç´¢å·¥å…·ï¼ˆæ ¹æ® .env ä¸­çš„ SEARCH_API é€‰æ‹©æœç´¢å¼•æ“ï¼‰
search_tool = get_web_search_tool(max_search_results=5)

# åœ¨ Agent ä¸­ä½¿ç”¨
tools = [search_tool]
```

#### æ”¯æŒçš„æœç´¢å¼•æ“

- **Tavily**: é«˜è´¨é‡æœç´¢ç»“æœï¼Œæ”¯æŒå›¾ç‰‡å’ŒåŸå§‹å†…å®¹
- **DuckDuckGo**: å…è´¹ï¼Œæ— éœ€ API key
- **Brave Search**: éœ€è¦ `BRAVE_SEARCH_API_KEY`
- **Arxiv**: å­¦æœ¯è®ºæ–‡æœç´¢
- **Searx**: å…ƒæœç´¢å¼•æ“
- **Wikipedia**: ç»´åŸºç™¾ç§‘æœç´¢

### 5. æç¤ºè¯æ¨¡æ¿ (`src.prompts`)

#### ä½¿ç”¨æç¤ºè¯æ¨¡æ¿

```python
from src.prompts import get_prompt_template, apply_prompt_template

# æ–¹æ³• 1: ç›´æ¥è·å–æ¨¡æ¿å†…å®¹ï¼ˆä¸åŒ…å«çŠ¶æ€å˜é‡ï¼‰
template_content = get_prompt_template("test")  # è¯»å– prompts/test.md

# æ–¹æ³• 2: åº”ç”¨æ¨¡æ¿ï¼ˆåŒ…å«çŠ¶æ€å˜é‡å’Œå½“å‰æ—¶é—´ï¼‰
from langgraph.prebuilt.chat_agent_executor import AgentState
state = {
    "messages": [...],
    "research_topic": "AI ç ”ç©¶"
}
messages_with_prompt = apply_prompt_template("test", state)
```

#### åˆ›å»ºæç¤ºè¯æ¨¡æ¿

åœ¨ `src/prompts/` ç›®å½•ä¸‹åˆ›å»º `.md` æ–‡ä»¶ï¼Œä½¿ç”¨ Jinja2 è¯­æ³•ï¼š

```markdown
---
CURRENT_TIME: {{ CURRENT_TIME }}
---

ä½ æ˜¯ä¸€ä¸ªå–„äºæŸ¥æ‰¾ä¿¡æ¯çš„ Agentã€‚

å½“å‰ç ”ç©¶ä¸»é¢˜ï¼š{{ research_topic }}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚
```

### 6. ä¸Šä¸‹æ–‡ç®¡ç† (`src.utils.context_manager`)

#### ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡

```python
from src.utils.context_manager import ContextManager
from functools import partial

# åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
token_limit = get_llm_token_limit_by_type("basic")
context_manager = ContextManager(
    token_limit=token_limit,
    preserve_prefix_message_count=3  # ä¿ç•™å‰ 3 æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·è¾“å…¥ï¼‰
)

# ä½œä¸ºé’©å­å‡½æ•°ä½¿ç”¨ï¼ˆåœ¨ Agent è°ƒç”¨å‰å‹ç¼©æ¶ˆæ¯ï¼‰
pre_model_hook = partial(context_manager.compress_messages)

# æ‰‹åŠ¨å‹ç¼©æ¶ˆæ¯
state = {"messages": [...]}
compressed_state = context_manager.compress_messages(state)

# æ£€æŸ¥ token æ•°é‡
token_count = context_manager.count_tokens(messages)
print(f"Token count: {token_count}")
```

### 7. JSON å·¥å…· (`src.utils.json_utils`)

#### JSON ä¿®å¤å’Œå‚æ•°æ¸…ç†

```python
from src.utils.json_utils import repair_json_output, sanitize_args

# ä¿®å¤å¯èƒ½æŸåçš„ JSON è¾“å‡º
json_string = '{"name": "test", "value": 123}'  # å¯èƒ½æœ‰æ ¼å¼é—®é¢˜
repaired = repair_json_output(json_string)

# æ¸…ç†å·¥å…·è°ƒç”¨å‚æ•°ï¼ˆé˜²æ­¢ç‰¹æ®Šå­—ç¬¦é—®é¢˜ï¼‰
args = '{"query": "[special] chars"}'
sanitized = sanitize_args(args)
```

### 8. å›¾çŠ¶æ€ç®¡ç† (`src.graph.types`)

#### å®šä¹‰è‡ªå®šä¹‰çŠ¶æ€

```python
from src.graph.types import State
from langchain_core.messages import HumanMessage

# State ç±»ç»§æ‰¿è‡ª MessagesStateï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
# - messages: æ¶ˆæ¯åˆ—è¡¨
# - locale: è¯­è¨€ç¯å¢ƒ
# - research_topic: ç ”ç©¶ä¸»é¢˜
# - observations: è§‚å¯Ÿç»“æœåˆ—è¡¨
# - current_plan: å½“å‰è®¡åˆ’
# - final_report: æœ€ç»ˆæŠ¥å‘Š
# - enable_clarification: æ˜¯å¦å¯ç”¨æ¾„æ¸…
# - goto: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹

state = State(
    messages=[HumanMessage(content="Hello")],
    research_topic="AI Research",
    locale="zh-CN"
)
```

## é…ç½® Agent å’Œ LLM æ˜ å°„

åœ¨ `src/config/agents.py` ä¸­å®šä¹‰ Agent ç±»å‹ä¸ LLM ç±»å‹çš„æ˜ å°„ï¼š

```python
AGENT_LLM_MAP: dict[LLMType, str] = {
    "planner": "basic",
    "researcher": "basic",
    "reasoner": "reasoning"
}
```

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ 1: åˆ›å»ºä¸€ä¸ªç®€å•çš„æœç´¢ Agent

```python
import os
import sys
from langchain_core.messages import HumanMessage

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨è·¯å¾„ä¸­
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.agents import create_agent_
from src.tools.search import get_web_search_tool
from src.prompts import get_prompt_template

# åˆ›å»º Agent
agent = create_agent_(
    agent_name="search_agent",
    agent_type="basic",
    tools=[get_web_search_tool(max_search_results=3)],
    prompt_template=get_prompt_template("test")
)

# è¿è¡Œ
result = agent.invoke(
    input={
        "messages": [
            HumanMessage(content="æŸ¥æ‰¾ä¸ LangChain ç›¸å…³çš„ä¿¡æ¯")
        ]
    },
    config={"recursion_limit": 10}
)

print(result["messages"][-1].content)
```

### ç¤ºä¾‹ 2: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†

```python
from src.llms import get_llm_by_type, get_llm_token_limit_by_type
from src.utils.context_manager import ContextManager
from functools import partial
from langchain_core.messages import HumanMessage, AIMessage

# è·å– LLM
llm = get_llm_by_type("basic")
token_limit = get_llm_token_limit_by_type("basic")

# åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
context_manager = ContextManager(
    token_limit=token_limit,
    preserve_prefix_message_count=2
)

# æ¨¡æ‹Ÿä¸€ä¸ªé•¿å¯¹è¯
messages = [
    HumanMessage(content="ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"),
    AIMessage(content="Python æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€..." * 100),  # å¾ˆé•¿çš„å›å¤
    HumanMessage(content="é‚£å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"),
]

# å‹ç¼©æ¶ˆæ¯
state = {"messages": messages}
compressed_state = context_manager.compress_messages(state)

print(f"åŸå§‹ token æ•°: {context_manager.count_tokens(messages)}")
print(f"å‹ç¼©å token æ•°: {context_manager.count_tokens(compressed_state['messages'])}")
```

## ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­å¯ä»¥é…ç½®ä»¥ä¸‹å˜é‡ï¼š

```bash
# æœç´¢å¼•æ“é€‰æ‹©
SEARCH_API=tavily

# æœç´¢å¼•æ“ API Keys
TAVILY_API_KEY=your_key
BRAVE_SEARCH_API_KEY=your_key

# LLM API Keysï¼ˆä¹Ÿå¯ä»¥åœ¨ config.yaml ä¸­é…ç½®ï¼‰
OPENAI_API_KEY=your_key
AZURE_OPENAI_ENDPOINT=your_endpoint
```
